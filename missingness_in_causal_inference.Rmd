---
title: "Estimating Missing Data's Effects on Causal Inference with Diff-in-Diff and IP-weighting"
author: "Nathen Byford"
date: "`r Sys.Date()`"
output: pdf_document
bibliography: clinical_missing.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse); theme_set(theme_bw())
library(gtsummary)

longi_score <- read_csv("data/longi_score_real_data.csv")

complete_case <- read_csv("data/complete_case.csv")
```

# Introduction

Missing data is a common problem among statistical analyses. Data can be missing due to a variety of reasons, form a subject not answering a question, to a subject leaving a study for one reason or another. Sometimes missing data is numerous and other times a study can have no missing data. Often times when a study has plentiful missing values classical statistical methods using the complete cases will be biased and something is needed to be done. 

In causal inference the issue of missing data is no different, there can be unintended bias introduced based on values that are missing. Causal inference methods might have more or less bias introduced by missing data due to the fact that we are trying to estimate counter factual outcomes, outcomes that don't exist in the first place. These estimates for the counter factual outcomes are based on the data observed in the study and if values are missing, information about the counter factuals is also being lost. Because of this I aim to investigate how causal inference estimates differ when there is missing data.


## Missingness in Data

It is important to understand the different types of missing data that can emerge in studies. Missing data can be classified into three main types: Missing Completely at Random (MCAR), Missing at Random (MAR), and Missing Not at Random (MNAR), each with distinct implications for analysis @little_statistical_2019. MCAR occurs when the missingness is entirely unrelated to both observed and unobserved data, meaning the data is missing purely by chance. In this case, traditional statistical techniques like complete case analysis remain valid, as the missing data introduces minimal bias. MAR arises when the probability of missing data is related to observed data but not to the missing values themselves. While this scenario introduces bias, it can often be addressed through techniques like multiple imputation that account for the relationship between observed variables and missingness. MNAR, on the other hand, is the most challenging type of missing data, where the missingness is directly related to the unobserved data. For example, patients may drop out of a study because their condition worsens. MNAR often introduces significant bias that cannot be addressed using standard techniques without strong assumptions. Specialized methods, such as machine learning-based imputation, are typically required to mitigate the impact of MNAR data.

# Methods

This study looks into the differences in the estimated treatment effect for compete case analysis in MNAR data compared to the imputed data estimated treatment effects. The following subsections go into detail about the methods of data imputation and causal inference to estimate the treatment effect.

## Data Imputation

Using Machine Learning techniques @haliduola_missing_2022 are able to impute MNAR data from a clinical trial for anxiety medication. The first step of the imputation was to cluster the data by drug response. This response curve is used to group better understand the differences between subjects based on their initial and continued response to the drug. Due to the time component of the data a recursive neural network was utilized in the data imputation. In addition due to the small sample size of some cluster over sampling was used in the training dataset. Because of this method, the data that are MNAR can be imputed with minimal loss of information and induced bias.

![Data Imputation Process](bimj2344-fig-0002-m.jpg){width=60%}

## Causal Inference Methods

Two causal inference methods will be used to estimate the treatment effect of the anxiety drug from the baseline checkup to the final checkup. Difference-in-Difference (Diff-in-Diff) and Inverse Probability Weighting (IP-weighting) are two widely used methods for estimating the average treatment effect (ATE) in causal inference. Diff-in-Diff compares changes in outcomes over time between treated and untreated groups, leveraging the assumption that trends would have been parallel in the absence of treatment. This method is particularly useful when pre-treatment data are available and helps account for time-invariant confounding. IP-weighting, on the other hand, uses propensity scores to create a pseudo-population where the treatment assignment is independent of observed covariates, thereby adjusting for potential confounding. Combining these methods can provide complementary insights: Diff-in-Diff focuses on changes over time while IP-weighting ensures balance in baseline characteristics, offering a robust approach to estimating the ATE in the presence of complex data structures or confounding variables.


# Analysis 

## Exploratory Data Analysis

The response variable is based on the Hamilton Anxiety Rating Scale (HAMA), therefore a lower score represents a better response. These scores where observed at a baseline at week 0 and then after treatment at week 1, 2, 4, and 6. Below in figure 2 we can see the scores of each subject at each checkup, untreated is on the left and treated subjects are on the right. The observations shown as a red "X" are ones that contain missing score values. There are 80 missing scores in the dataset.

```{r, fig.align='center', fig.height=2.5, fig.width=5, message=FALSE, warning=FALSE, fig.cap="Observed responses by Week"}

longi_score |> 
  mutate(
    "Incomplete" = ifelse(id %in% complete_case$id, FALSE, TRUE)
  ) |> 
  ggplot(aes(x = week, y = score)) +
  geom_jitter(aes(shape = Incomplete, color = Incomplete), width = .15) +
  geom_smooth() +
  facet_wrap(~treat) +
  scale_color_manual(values = c("black", "red")) +
  scale_shape_manual(values = c(16, 4)) +
  labs(title = "Weekly Response with all Observed Values") +
  theme(legend.position = "none")
```

In the following tables we can see how these missing scores are distributed. We can see in table 3 the split of the missing values between treated and untreated. The split is fairly even with 38 missing scores in the treatment group and 42 missing scores in the untreated group. We can see that there is slightly more missing values in the untreated group. Looking in table 4 the missing values increase as time goes on in the study. This is possibly due to the drug potentially not working or even the opposite. This time related missingness is a sign that there can be a reason the data are missing and a pattern that could be causing the missing.


## Complete Case analysis

Using the complete cases in the dataset 80 observations are lost due to missing response values. Using complete case analysis will most likely result in biased estimated due to the previously mentioned MNAR nature of the data. The goal of causal inference is to estimate the average treatment effect and doing so often includes estimating counter factual outcomes. The estimated values of the counter factual outcome may be biased by the missing information in the missing data. More sophisticated causal inference methods account for the fact that the counter factuals are missing themselves and may have less bias estimates.

The first method used is Diff-in-Diff, this method relies on the assumptions that the treatment and control are similar with parallel trends in the outcome. In figure 3 the trend lines for the complete case analysis can be seen. Most importantly we can see that the trend lines from baseline to week 1 are parallel, if there is some period before the drug takes effect this provides evidence that the parallel trends assumption is correct. Additionally Knowing that the data comes from a clinical trial we can say that the the treatment and control were most likely well randomized.

Fitting the Diff-in-Diff model the results are shown in table 1 are not significant at the 5% significance level. What we do see is a a slight decrease in the score for the treated group compared to the control group. The 95% confidence interval for the ATE, shown as DID, is between -1.1 and 0.003. This interval includes 0 so we cannot state that the ATE is not 0 at this significance level.

The next method tested was IP-weighting, this method relies on the additional assumption of positivity. Calculating the weights results all positive values between 0 and 1 satisfying positivity. The results for IP-weighting are shown in table 2. In this table we have the treatment variable, week/time variable, and interaction term between the two. This interaction term is what provides an estimate of the ATE.

\newpage
```{r, message=FALSE}

complete_data <- complete_case |> 
  filter(week %in% c(0, 6))

did_reg <- lm(score ~ treat + week + DID, 
              data = complete_data)

tbl_regression(did_reg) |> 
  modify_caption(caption = "Difference in difference estimates week 0 to 6")
```

```{r, message=FALSE}
ps_mod <- complete_case |> 
  filter(week %in% c(0, 6)) |> 
  glm(treat ~ sex + base, family = "binomial", data = _)

ps <- as.numeric(predict(ps_mod, type = "response"))

w <- if_else(
  complete_data$treat == 1, ps, 1 - ps
)

wls <- lm(score ~ treat + week + treat*week, 
              data = complete_data, weights = w)

tbl_regression(wls) |> 
  modify_caption(caption = "IP-weighting Estimates week 0 to 6")
```

## Imputed Values analysis

After imputing the missing values using the machine learning approach, the same causal inference methods are applied to the imputed dataset to assess how imputing missing data affects the analysis. These imputed values can be seen in figure 4 along with their trend lines. The imputed values has a more conservative trend line with some more higher HAMA scores at time points 4 and 6.

For the Diff-in-Diff analysis Table 3, the treatment effect estimate (DID) for weeks 0 to 6 was -0.54, with a 95% confidence interval of -1.0 to -0.07. This interval excludes zero, indicating a significant treatment effect at the 5% level (p = 0.025). Compared to the complete case analysis, the confidence interval is narrower, suggesting improved precision in the estimate due to the inclusion of imputed data.

Similarly, the IP-weighting results Table 4 show an interaction term estimate of -0.61 (95% CI: -1.1 to -0.14), which is also statistically significant (p = 0.011). This represents a slight change from the complete case analysis, where the interaction term was estimated at -0.58 with a wider confidence interval of -1.1 to -0.05. The narrower confidence intervals observed with the imputed dataset highlight the advantage of leveraging machine learning techniques to handle MNAR data, as the imputed values increase the information available for analysis and reduce variability in the estimates.

The imputed data results demonstrate the potential for more accurate and reliable causal inference when missing data is accounted for, particularly in scenarios where missingness is not completely at random. This underscores the importance of adopting advanced imputation methods in studies with substantial missingness to minimize bias and improve the robustness of findings.

```{r, message=FALSE}
imput_data <- read_csv("data/pred_real_data.csv")

imputed_values <- imput_data |> 
  summarise(
    value = mean(predict),
    .by = c(id, week)
  )

new_data <- left_join(longi_score, imputed_values, by = c("id", "week")) |> 
  mutate(score = if_else(is.na(score), value, score)) |> 
  select(-value)
```


\newpage
```{r, message=FALSE}

did_reg_i <- new_data |> 
  filter(week %in% c(0, 6)) |>
  mutate("DID" = treat * week) |> 
  lm(score ~ treat + week + DID, 
              data = _)

tbl_regression(did_reg_i) |> 
  modify_caption(caption = "Difference in difference estimates with imputed values weeks 0 to 6")
```

```{r, message=FALSE}

ps_mod_i <- new_data |> 
  filter(week %in% c(0, 6)) |> 
  glm(treat ~ sex + base, family = "binomial", data = _)

new_dat <- new_data |> 
  filter(week %in% c(0, 6))

ps_i <- as.numeric(predict(ps_mod_i, type = "response"))

w_i <- if_else(
  new_dat$treat == 1, ps_i, 1 - ps_i
)

wls_i <- new_data |> 
  filter(week %in% c(0, 6)) |> 
  lm(score ~ treat + week + treat*week, 
              data = _, weights = w_i)

tbl_regression(wls_i) |> 
  modify_caption(caption = "IP-weighting estimates with imputed values weeks 0 to 6")
```

# Conclusion and Discussion

The analysis highlights the impact of missing data on causal inference estimates and the benefits of using imputation methods to address MNAR data. When comparing the results from complete case analysis (Tables 1 and 2) with those from the imputed dataset (Tables 3 and 4), several key differences emerge. These values are also provided in table 5 for easy comparison. For both Difference-in-Difference (Diff-in-Diff) and IP-weighting, the imputed dataset yields slightly different point estimates. For instance, the estimated treatment effect from Diff-in-Diff changed marginally from -0.51 (95% CI: -1.1, 0.03) to -0.54 (95% CI: -1.0, -0.07). Similarly, for IP-weighting, the interaction term's estimate shifted from -0.58 (95% CI: -1.1, -0.05) to -0.61 (95% CI: -1.1, -0.14).

More notably, the confidence intervals in the imputed dataset are narrower across both methods. This suggests that imputing the missing data reduces the variability in the estimates, likely by leveraging the additional information provided by the machine learning imputation process. For example, the confidence interval for the Diff-in-Diff treatment effect became tighter, providing greater precision and allowing significance to be detected at the 5% level (p = 0.025). These narrower intervals indicate increased statistical power when accounting for missing data, underscoring the value of sophisticated imputation techniques in handling MNAR scenarios.

Overall, the results demonstrate that complete case analysis risks bias and reduced precision due to the exclusion of incomplete observations. By contrast, imputation improves both the validity and reliability of causal effect estimates. These findings emphasize the importance of employing advanced data imputation strategies in studies with substantial missingness, particularly when the missing data mechanism is not random.

```{r}
tibble(
  Data = c("Complete Case", "", "Imputed Data", ""),
  Method = rep(c("Diff-in-Diff", "IW-Weighting"), 2),
  ATE = c(did_reg$coefficients[4], wls$coefficients[4], did_reg_i$coefficients[4], wls_i$coefficients[4]),
  `95% CI` = c(
    str_c(round(confint(did_reg)[4,1], 2), round(confint(did_reg)[4,2], 2), sep = ", "),
    str_c(round(confint(wls)[4,1], 2), round(confint(wls)[4,2], 2), sep = ", "),
    str_c(round(confint(did_reg_i)[4,1], 2), round(confint(did_reg_i)[4,2], 2), sep = ", "),
    str_c(round(confint(wls_i)[4,1], 2), round(confint(wls_i)[4,2], 2), sep = ", ")
  ),
  "p-value" = c(
    summary(did_reg)$coefficients[4,4],
    summary(wls)$coefficients[4,4],
    summary(did_reg_i)$coefficients[4,4],
    summary(wls_i)$coefficients[4,4]
  )
) |> 
  knitr::kable(digits = 2, caption = "Estimates from all methods")
```


\newpage
# References

<div id="refs"></div>

# Appendix

## A1: EDA

```{r, warning=FALSE, tab.cap="Missing Values by Treatment"}
longi_score |> 
  summarise(
    `NA count` = sum(is.na(score)),
    .by = treat
  ) |> 
  rename("Treatment" = treat) |> 
  flextable::flextable()
```


```{r, warning=FALSE, tab.cap="Missing Values by Week"}
longi_score |> 
  summarise(
    `NA count` = sum(is.na(score)),
    .by = week
  ) |> 
  rename("Week" = week) |> 
  flextable::flextable()
```

\newpage

## A2: Complete case analysis

```{r, message=FALSE, warning=FALSE, fig.width=5, fig.height=2.5, fig.align='center', fig.cap="Treatment and Controll Trend Lines by Week"}
complete_case |> 
  ggplot(aes(x = week, y = score, color = as.factor(treat))) +
  geom_jitter(width = 0.15, alpha = .7) +
  geom_smooth(se = FALSE, alpha = .7) +
  scale_color_manual(values = c("steelblue", "goldenrod")) +
  labs(title = "Trend lines by treatment group", color = "Treatment")
```

## A3: Imputed Data

```{r, message=FALSE, warning=FALSE, fig.width=5, fig.height=3, fig.align='center', fig.cap="Plot of imputed data values and trend"}

new_data |> 
  ggplot(aes(x = week, y = score)) +
  geom_jitter(width = .15) +
  geom_smooth(aes(color = "Imputed"), se = FALSE) +
  geom_smooth(data = longi_score, se = FALSE, aes(color = "Complete case")) +
  facet_wrap(~treat) +
  labs(title = "Weekly Response with Imputed Values",
       color = "Line") +
  scale_color_manual(values = c("cornflowerblue", "forestgreen")) +
  theme(legend.position = "bottom")
```

